{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi4MsVc5arWq"
      },
      "source": [
        "# CMU 11424/11824 Spring 2024: Reinflection and Paradigm Completion\n",
        "\n",
        "## Baselines for Unimorph Reinflection Task\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YMD9gcja2Fq"
      },
      "source": [
        "## Download Datasets\n",
        "\n",
        "Data should be downloaded from Canvas and uploaded to the Colab filesystem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCyOu-hkal9X",
        "outputId": "2c168ba6-ec74-42cc-a1bf-132f4d495c93"
      },
      "outputs": [],
      "source": [
        "# %cd /content/\n",
        "# !rm -rf dataset\n",
        "# !unzip dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Zm8gSn6b58q"
      },
      "source": [
        "## Performance Measures\n",
        "\n",
        "Here, we are using exact match for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xOW7cEEfa9Gy"
      },
      "outputs": [],
      "source": [
        "import unicodedata\n",
        "\n",
        "def evaluate(gold, pred):\n",
        "\n",
        "  preds = [int(unicodedata.normalize(\"NFC\",p)==unicodedata.normalize(\"NFC\",g)) for p, g in zip(pred, gold)]\n",
        "  if len(preds) == 0:\n",
        "    return 0\n",
        "  return sum(preds)/len(preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReFfxXCzdisX"
      },
      "source": [
        "## Non-Neural Baseline\n",
        "\n",
        "This method is pulled from the Unimorph non-neural baseline for Sigmorphon Reinflection Shared Task 2022."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qRTISfLidiGl"
      },
      "outputs": [],
      "source": [
        "import sys, os, getopt, re\n",
        "from functools import wraps\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZiFDtfnPd2A2"
      },
      "outputs": [],
      "source": [
        "def hamming(s,t):\n",
        "    return sum(1 for x,y in zip(s,t) if x != y)\n",
        "\n",
        "\n",
        "def halign(s,t):\n",
        "    \"\"\"Align two strings by Hamming distance.\"\"\"\n",
        "    slen = len(s)\n",
        "    tlen = len(t)\n",
        "    minscore = len(s) + len(t) + 1\n",
        "    # get the minimum dist \n",
        "    for upad in range(0, len(t)+1):\n",
        "        upper = '_' * upad + s + (len(t) - upad) * '_'\n",
        "        lower = len(s) * '_' + t\n",
        "        # print(f\"upper: {upper}, lower: {lower}\")\n",
        "        score = hamming(upper, lower)\n",
        "        if score < minscore:\n",
        "            bu = upper\n",
        "            bl = lower\n",
        "            minscore = score\n",
        "    # the other way around \n",
        "    for lpad in range(0, len(s)+1):\n",
        "        upper = len(t) * '_' + s\n",
        "        lower = (len(s) - lpad) * '_' + t + '_' * lpad\n",
        "        # print(f\"upper: {upper}, lower: {lower}\")\n",
        "        score = hamming(upper, lower)\n",
        "        if score < minscore:\n",
        "            bu = upper\n",
        "            bl = lower\n",
        "            minscore = score\n",
        "\n",
        "    zipped = zip(bu,bl)\n",
        "    # print(f\"bu: {bu}, bl: {bl}\")\n",
        "    newin  = ''.join(i for i,o in zipped if i != '_' or o != '_')\n",
        "    newout = ''.join(o for i,o in zipped if i != '_' or o != '_')\n",
        "    return newin, newout\n",
        "\n",
        "\n",
        "def levenshtein(s, t, inscost = 1.0, delcost = 1.0, substcost = 1.0):\n",
        "    \"\"\"Recursive implementation of Levenshtein, with alignments returned.\"\"\"\n",
        "    @memolrec\n",
        "    def lrec(spast, tpast, srem, trem, cost):\n",
        "        if len(srem) == 0:\n",
        "            return spast + len(trem) * '_', tpast + trem, '', '', cost + len(trem)\n",
        "        if len(trem) == 0:\n",
        "            return spast + srem, tpast + len(srem) * '_', '', '', cost + len(srem)\n",
        "\n",
        "        addcost = 0\n",
        "        if srem[0] != trem[0]:\n",
        "            addcost = substcost\n",
        "\n",
        "        return min((lrec(spast + srem[0], tpast + trem[0], srem[1:], trem[1:], cost + addcost),\n",
        "                   lrec(spast + '_', tpast + trem[0], srem, trem[1:], cost + inscost),\n",
        "                   lrec(spast + srem[0], tpast + '_', srem[1:], trem, cost + delcost)),\n",
        "                   key = lambda x: x[4])\n",
        "\n",
        "    answer = lrec('', '', s, t, 0)\n",
        "    return answer[0],answer[1],answer[4]\n",
        "\n",
        "\n",
        "def memolrec(func):\n",
        "    \"\"\"Memoizer for Levenshtein.\"\"\"\n",
        "    cache = {}\n",
        "    @wraps(func)\n",
        "    def wrap(sp, tp, sr, tr, cost):\n",
        "        if (sr,tr) not in cache:\n",
        "            res = func(sp, tp, sr, tr, cost)\n",
        "            cache[(sr,tr)] = (res[0][len(sp):], res[1][len(tp):], res[4] - cost)\n",
        "        return sp + cache[(sr,tr)][0], tp + cache[(sr,tr)][1], '', '', cost + cache[(sr,tr)][2]\n",
        "    return wrap\n",
        "\n",
        "\n",
        "def alignprs(lemma, form):\n",
        "    \"\"\"Break lemma/form into three parts:\n",
        "    IN:  1 | 2 | 3\n",
        "    OUT: 4 | 5 | 6\n",
        "    1/4 are assumed to be prefixes, 2/5 the stem, and 3/6 a suffix.\n",
        "    1/4 and 3/6 may be empty.\n",
        "    \"\"\"\n",
        "\n",
        "    al = levenshtein(lemma, form, substcost = 1.1) # Force preference of 0:x or x:0 by 1.1 cost\n",
        "    alemma, aform = al[0], al[1]\n",
        "    # leading spaces\n",
        "    lspace = max(len(alemma) - len(alemma.lstrip('_')), len(aform) - len(aform.lstrip('_')))\n",
        "    # trailing spaces\n",
        "    tspace = max(len(alemma[::-1]) - len(alemma[::-1].lstrip('_')), len(aform[::-1]) - len(aform[::-1].lstrip('_')))\n",
        "    return alemma[0:lspace], alemma[lspace:len(alemma)-tspace], alemma[len(alemma)-tspace:], aform[0:lspace], aform[lspace:len(alemma)-tspace], aform[len(alemma)-tspace:]\n",
        "\n",
        "\n",
        "def prefix_suffix_rules_get(lemma, form):\n",
        "    \"\"\"Extract a number of suffix-change and prefix-change rules\n",
        "    based on a given example lemma+inflected form.\"\"\"\n",
        "    lp,lr,ls,fp,fr,fs = alignprs(lemma, form) # Get six parts, three for in three for out\n",
        "\n",
        "    # Suffix rules\n",
        "    ins  = lr + ls + \">\"\n",
        "    outs = fr + fs + \">\"\n",
        "    srules = set()\n",
        "    for i in range(min(len(ins), len(outs))):\n",
        "        srules.add((ins[i:], outs[i:]))\n",
        "    srules = {(x[0].replace('_',''), x[1].replace('_','')) for x in srules}\n",
        "\n",
        "    # Prefix rules\n",
        "    prules = set()\n",
        "    if len(lp) >= 0 or len(fp) >= 0:\n",
        "        inp = \"<\" + lp\n",
        "        outp = \"<\" + fp\n",
        "        for i in range(0,len(fr)):\n",
        "            prules.add((inp + fr[:i],outp + fr[:i]))\n",
        "            prules = {(x[0].replace('_',''), x[1].replace('_','')) for x in prules}\n",
        "\n",
        "    return prules, srules\n",
        "\n",
        "\n",
        "def apply_best_rule(lemma, msd, allprules, allsrules):\n",
        "    \"\"\"Applies the longest-matching suffix-changing rule given an input\n",
        "    form and the MSD. Length ties in suffix rules are broken by frequency.\n",
        "    For prefix-changing rules, only the most frequent rule is chosen.\"\"\"\n",
        "\n",
        "    bestrulelen = 0\n",
        "    base = \"<\" + lemma + \">\"\n",
        "    if msd not in allprules and msd not in allsrules:\n",
        "        return lemma # Haven't seen this inflection, so bail out\n",
        "\n",
        "    if msd in allsrules:\n",
        "        applicablerules = [(x[0],x[1],y) for x,y in allsrules[msd].items() if x[0] in base]\n",
        "        if applicablerules:\n",
        "            bestrule = max(applicablerules, key = lambda x: (len(x[0]), x[2], len(x[1])))\n",
        "            base = base.replace(bestrule[0], bestrule[1])\n",
        "\n",
        "    if msd in allprules:\n",
        "        applicablerules = [(x[0],x[1],y) for x,y in allprules[msd].items() if x[0] in base]\n",
        "        if applicablerules:\n",
        "            bestrule = max(applicablerules, key = lambda x: (x[2]))\n",
        "            base = base.replace(bestrule[0], bestrule[1])\n",
        "\n",
        "    base = base.replace('<', '')\n",
        "    base = base.replace('>', '')\n",
        "    return base\n",
        "\n",
        "\n",
        "def numleadingsyms(s, symbol):\n",
        "    return len(s) - len(s.lstrip(symbol))\n",
        "\n",
        "\n",
        "def numtrailingsyms(s, symbol):\n",
        "    return len(s) - len(s.rstrip(symbol))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v33lgvfnd982",
        "outputId": "f06bc956-d2b2-4cac-99a3-f5b59c5aefa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['абджхэ', 'абджхэмэ', 'абджхыу', 'абджм', 'абджр', 'абджхэр', 'абджу', 'абджхэмкӏэ', 'абджхэкӏэ', 'абджмкӏэ', 'абджкӏэ', 'абдж', 'балыджэхэ', 'балыджэхэмэ', 'балыджэхыу', 'балыджэм', 'балыджэр', 'балыджэхэр', 'балыджэу', 'балыджэхэмкӏэ']\n"
          ]
        }
      ],
      "source": [
        "lang = 'kbd'\n",
        "\n",
        "allprules, allsrules = {}, {}\n",
        "lines = [line.strip() for line in open(f\"dataset/{lang}.train.tsv\", \"r\") if line != '\\n']\n",
        "trainlemmas = set()\n",
        "trainmsds = set()\n",
        "\n",
        "# First, test if language is predominantly suffixing or prefixing\n",
        "# If prefixing, work with reversed strings\n",
        "prefbias, suffbias = 0,0\n",
        "for l in lines:\n",
        "  lemma, form, msd = l.split(u'\\t')\n",
        "  trainlemmas.add(lemma)\n",
        "  trainmsds.add(msd)\n",
        "  aligned = halign(lemma, form)\n",
        "#   print(\"aligned: \", aligned)\n",
        "#   assert True == False\n",
        "  if ' ' not in aligned[0] and ' ' not in aligned[1] and '-' not in aligned[0] and '-' not in aligned[1]:\n",
        "      prefbias += numleadingsyms(aligned[0],'_') + numleadingsyms(aligned[1],'_')\n",
        "      suffbias += numtrailingsyms(aligned[0],'_') + numtrailingsyms(aligned[1],'_')\n",
        "for l in lines: # Read in lines and extract transformation rules from pairs\n",
        "    lemma, form, msd = l.split(u'\\t')\n",
        "    if prefbias > suffbias:\n",
        "        lemma = lemma[::-1]\n",
        "        form = form[::-1]\n",
        "    prules, srules = prefix_suffix_rules_get(lemma, form)\n",
        "\n",
        "    if msd not in allprules and len(prules) > 0:\n",
        "        allprules[msd] = {}\n",
        "    if msd not in allsrules and len(srules) > 0:\n",
        "        allsrules[msd] = {}\n",
        "\n",
        "    for r in prules:\n",
        "        if (r[0],r[1]) in allprules[msd]:\n",
        "            allprules[msd][(r[0],r[1])] = allprules[msd][(r[0],r[1])] + 1\n",
        "        else:\n",
        "            allprules[msd][(r[0],r[1])] = 1\n",
        "\n",
        "    for r in srules:\n",
        "        if (r[0],r[1]) in allsrules[msd]:\n",
        "            allsrules[msd][(r[0],r[1])] = allsrules[msd][(r[0],r[1])] + 1\n",
        "        else:\n",
        "            allsrules[msd][(r[0],r[1])] = 1\n",
        "\n",
        "evallines = [line.strip() for line in open(f\"dataset/{lang}.dev.tsv\", \"r\") if line != '\\n']\n",
        "outfile = open(f\"{lang}.dev.txt\", \"w\")\n",
        "\n",
        "pred = []\n",
        "gold = []\n",
        "\n",
        "for l in evallines:\n",
        "    lemma, correct, msd = l.split(u'\\t')\n",
        "    # lemma, msd = l.split(u'\\t')\n",
        "    if prefbias > suffbias:\n",
        "        lemma = lemma[::-1]\n",
        "    outform = apply_best_rule(lemma, msd, allprules, allsrules)\n",
        "    if prefbias > suffbias:\n",
        "        outform = outform[::-1]\n",
        "        lemma = lemma[::-1]\n",
        "    pred.append(outform)\n",
        "    # gold.append(correct)\n",
        "\n",
        "    outfile.write(outform + \"\\n\")\n",
        "\n",
        "print(pred[:20])\n",
        "# print(gold[:20])\n",
        "# print(evaluate(pred, gold))\n",
        "\n",
        "outfile.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXu2vI1IE7bw"
      },
      "source": [
        "## Neural Baseline\n",
        "\n",
        "This method is pulled from the Unimorph non-neural baseline for Sigmorphon Reinflection Shared Task 2022."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!conda install python==3.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_LpB2Dzf0ME",
        "outputId": "5f83858a-03ea-4da3-f812-c90732ba62fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement python==3.7 (from versions: none)\n",
            "ERROR: No matching distribution found for python==3.7\n",
            "ERROR: Could not find a version that satisfies the requirement torch==1.13.1 (from versions: 2.2.0, 2.2.1)\n",
            "ERROR: No matching distribution found for torch==1.13.1\n"
          ]
        }
      ],
      "source": [
        "# !git clone https://github.com/shijie-wu/neural-transducer/\n",
        "!pip install --upgrade python==3.7\n",
        "!pip install --upgrade torch==1.13.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.13.1+cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEo4ZPAlFKxP",
        "outputId": "ac2b50d6-3df9-4ede-ef20-bb39b144c0d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WinError 2] The system cannot find the file specified: 'neural-transducer/'\n",
            "c:\\My Document\\CMU\\CMU Courses\\11-824\\Projects\\11824_Subword_Modeling\\proj2\\neural-transducer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'make' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "run_train.sh: line 1: $'\\r': command not found\n",
            "run_train.sh: line 6: $'\\r': command not found\n",
            "run_train.sh: line 15: $'\\r': command not found\n",
            "run_train.sh: line 24: $'\\r': command not found\n",
            "run_train.sh: line 26: $'\\r': command not found\n",
            "run_train.sh: line 27: python: command not found\n"
          ]
        }
      ],
      "source": [
        "run_train = \"\"\"\n",
        "#!/bin/bash\n",
        "lang=$1\n",
        "arch=${2:-tagtransformer}\n",
        "suff=$3\n",
        "\n",
        "lr=0.001\n",
        "scheduler=warmupinvsqr\n",
        "epochs=100\n",
        "warmup=100\n",
        "beta2=0.98       # 0.999\n",
        "label_smooth=0.1 # 0.0\n",
        "total_eval=50\n",
        "bs=400 # 256\n",
        "\n",
        "# transformer\n",
        "layers=4\n",
        "hs=1024\n",
        "embed_dim=256\n",
        "nb_heads=4\n",
        "#dropout=${2:-0.3}\n",
        "dropout=0.3\n",
        "ckpt_dir=checkpoints/sig22\n",
        "\n",
        "path=../dataset\n",
        "\n",
        "python src/train.py \\\n",
        "    --dataset sigmorphon17task1 \\\n",
        "    --train $path/$lang.train.tsv \\\n",
        "    --dev $path/$lang.dev.tsv \\\n",
        "    --test $path/$lang.testhidden.tsv \\\n",
        "    --model $ckpt_dir/$arch/$lang \\\n",
        "    --decode greedy --max_decode_len 32 \\\n",
        "    --embed_dim $embed_dim --src_hs $hs --trg_hs $hs --dropout $dropout --nb_heads $nb_heads \\\n",
        "    --label_smooth $label_smooth --total_eval $total_eval \\\n",
        "    --src_layer $layers --trg_layer $layers --max_norm 1 --lr $lr --shuffle \\\n",
        "    --arch $arch --gpuid 0 --estop 1e-8 --bs $bs --epochs $epochs \\\n",
        "    --scheduler $scheduler --warmup_steps $warmup --cleanup_anyway --beta2 $beta2 --bestacc\n",
        "\"\"\"\n",
        "\n",
        "%cd neural-transducer/\n",
        "with open('run_train.sh', 'w') as f:\n",
        "  f.write(run_train)\n",
        "!make\n",
        "!bash run_train.sh xty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "jL4rmkOiCNxD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "neural-transducer/run_train.sh: line 2: $'\\r': command not found\n",
            "neural-transducer/run_train.sh: line 3: conda: command not found\n",
            "neural-transducer/run_train.sh: line 3: $'\\r': command not found\n",
            "neural-transducer/run_train.sh: line 4: conda: command not found\n",
            "neural-transducer/run_train.sh: line 5: $'\\r': command not found\n",
            "neural-transducer/run_train.sh: line 6: $'\\r': command not found\n",
            "neural-transducer/run_train.sh: line 28: $'\\r': command not found\n",
            "neural-transducer/run_train.sh: line 29: python: command not found\n"
          ]
        }
      ],
      "source": [
        "!bash neural-transducer/run_train.sh xty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\My Document\\\\CMU\\\\CMU Courses\\\\11-824\\\\Projects\\\\11824_Subword_Modeling\\\\proj2'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
